
使用kubeadm安装kuberneters1.17.3

# 系统环境准备
使用3台centos7.2操作系统，机器分别角色是master,worknode,worknode  
1、设置主机名  
hostnamectl set-hostname master  
2、编辑修改/etc/hosts  
cat <<EOF >>/etc/hosts  
10.10.10.1 master  
10.10.10.2 node1  
10.10.10.3 node2  
EOF  
3、关闭防火墙，禁止交换swap  
systemctl stop firewalld  
systemctl disable firewalld  
setenforce 0  
sed -i "s/^SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config  
swapoff -a  
sed -i 's/.*swap.*/#&/' /etc/fstab  
如果是云主机一般不需要上述操作，默认关闭交换内存，关闭防火墙。  
4、配置内核参数，IPv4流量传递到iptables的链上  
cat > /etc/sysctl.d/k8s.conf <<EOF  
net.bridge.bridge-nf-call-ip6tables = 1  
net.bridge.bridge-nf-call-iptables = 1  
net.ipv4.ip_forward = 1  
EOF  
sysctl --system  
如果遇到/proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1  
解决方案：  
        echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables  
        echo 1 > /proc/sys/net/bridge/bridge-nf-call-ip6tables  		
5、添加国内Kubernetes源  
cat <<EOF > /etc/yum.repos.d/kubernetes.repo  
[kubernetes]  
name=Kubernetes  
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/  
enabled=1  
gpgcheck=1  
repo_gpgcheck=1  
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg  
EOF  
6、添加docker 源  
cat  <<EOF > /etc/yum.repos.d/docker.repo  
[docker-ce-stable]  
name=Docker CE Stable - $basearch  
baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/$basearch/stable  
enabled=1  
gpgcheck=1  
gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg  
EOF  
k8s安装  
7、每台机器安装  
yum install kubelet kubeadm kubectl  
systemctl enable kubelet  

# k8s安装  
1、部署master 节点  
在master节点初始化  
kubeadm init --kubernetes-version=1.17.3 --apiserver-advertise-address=10.192.126.118 --image-repository  registry.aliyuncs.com/google_containers --service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16  
如果出现  
detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd"  
解决办法：  
修改或创建/etc/docker/daemon.json，加入下述内容：  
{  
  "exec-opts": ["native.cgroupdriver=systemd"]  
}  
[ERROR DirAvailable--var-lib-etcd]: /var/lib/etcd is not empty  
解决办法：  
rm -rf /var/lib/etcd  
安装成功后如下信息需要记住  
Your Kubernetes control-plane has initialized successfully!  
To start using your cluster, you need to run the following as a regular user:  
  mkdir -p $HOME/.kube  
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  
  sudo chown $(id -u):$(id -g) $HOME/.kube/config  

You should now deploy a pod network to the cluster.  
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:  
  https://kubernetes.io/docs/concepts/cluster-administration/addons/  

Then you can join any number of worker nodes by running the following on each as root:  

kubeadm join 10.192.126.118:6443 --token cjcepg.zlpbj2advlh0k5e5 \  
    --discovery-token-ca-cert-hash sha256:825f8a4ebe2da9187cde8351805df71e099a81c2a9f9d33f7456eb3fbf4cae0c  
	
如果遇到kubectl get nodes之类的命令出现error: the server doesn't have a resource type "nodes"  
这个是因为权限问题，需要使用sudo，当前是root账号还需要sudo运行，可以尝试运行sudo -s  

1、创建成功后使用kubectl get pods --all-namespaces查看pod的健康性，在实际操作我遇到了  
kube-system   coredns-9d85f5447-mk9cq                       0/1     ContainerCreating   0          12m  
kube-system   coredns-9d85f5447-wjpk7                       0/1     ContainerCreating   0          12m  
是用kubectl describe pod coredns-9d85f5447-mk9cq -n kube-system查看pod信息，主要错误是  
network: error getting ClusterInformation，https://10.43.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default  
这里一般是分析netowrkplugin，配置文件路径/etc/cni/net.d，我的情况是因为之前机器CNI插件没有  
清理干净，当前选择是canal，所以需要删除10-calico.conflist，修改10-canal.yaml内容。  
修改参考https://docs.projectcalico.org/reference/cni-plugin/configuration  

2、日志查看 journalctl -f -u kubelet |grep -i error -C 500  

# k8s集群卸载
kubeadm reset -f  
modprobe -r ipip  
lsmod  
rm -rf ~/.kube/  
rm -rf /etc/kubernetes/  
rm -rf /etc/systemd/system/kubelet.service.d  
rm -rf /etc/systemd/system/kubelet.service  
rm -rf /usr/bin/kube*  
rm -rf /etc/cni  
rm -rf /opt/cni  
rm -rf /var/lib/etcd  
rm -rf /var/etcd  
ifconfig flannel.1 down  
ip link delete flannel.1  
yum clean all  


使用配置文件进行集群初始化  
1、kubeadm config print init-defaults ClusterConfiguration >kubeadm-config.conf  
2、修改kubeadm-config.conf  
kubeadm init --config kubeadm-config.yaml  

apiVersion: kubeadm.k8s.io/v1beta2  
bootstrapTokens:  
- groups:  
  - system:bootstrappers:kubeadm:default-node-token  
  token: abcdef.0123456789abcdef  
  ttl: 24h0m0s  
  usages:  
  - signing  
  - authentication  
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.192.126.118
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: test4.leapmotor.com
  taints:
  - effect: NoSchedule  
    key: node-role.kubernetes.io/master  
  ---
apiServer:  
  timeoutForControlPlane: 4m0s  
apiVersion: kubeadm.k8s.io/v1beta2  
certificatesDir: /etc/kubernetes/pki  
clusterName: kubernetes  
controllerManager: {}  
dns:  
  type: CoreDNS  
etcd:  
  local:  
    dataDir: /var/lib/etcd  
imageRepository: registry.aliyuncs.com/google_containers  
kind: ClusterConfiguration  
kubernetesVersion: v1.17.0  
networking:  
  dnsDomain: cluster.local  
  serviceSubnet: 10.96.0.0/12  
  podSubnet: 10.244.0.0/16  
scheduler: {}  

3、修改kubelet的启动参数  
vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf  
ExecStart=/usr/bin/kubelet --logtostderr=false --log-dir=/var/log/kubernetes(确保/var/log/kubernetes路径正确）  
systemctl daemon-reload  
